[{"path":[]},{"path":"https://jianhuig.github.io/FairnessTutorial/articles/TwoGroup.html","id":"missing-data","dir":"Articles","previous_headings":"Data Preprocessing","what":"Missing Data","title":"Binary Protected Attributes","text":"","code":"# Calculate the number of missing values per column missing_values <- sapply(mimic, function(x) sum(is.na(x)))  # Calculate the percentage of missing values per column missing_values_percentage <- sapply(mimic, function(x) sum(is.na(x)) / length(x) * 100)  # Combine the results into a data frame for easy viewing missing_data_summary <- data.frame(Number_of_Missing_Values = missing_values,                                     Percentage = missing_values_percentage)  # Print the summary print(missing_data_summary) #>                    Number_of_Missing_Values  Percentage #> aline_flg                                 0  0.00000000 #> icu_los_day                               0  0.00000000 #> hospital_los_day                          0  0.00000000 #> age                                       0  0.00000000 #> gender_num                                1  0.05630631 #> weight_first                            110  6.19369369 #> bmi                                     466 26.23873874 #> sapsi_first                              85  4.78603604 #> sofa_first                                6  0.33783784 #> service_unit                              0  0.00000000 #> service_num                               0  0.00000000 #> day_icu_intime                            0  0.00000000 #> day_icu_intime_num                        0  0.00000000 #> hour_icu_intime                           0  0.00000000 #> hosp_exp_flg                              0  0.00000000 #> icu_exp_flg                               0  0.00000000 #> day_28_flg                                0  0.00000000 #> mort_day_censored                         0  0.00000000 #> censor_flg                                0  0.00000000 #> sepsis_flg                                0  0.00000000 #> chf_flg                                   0  0.00000000 #> afib_flg                                  0  0.00000000 #> renal_flg                                 0  0.00000000 #> liver_flg                                 0  0.00000000 #> copd_flg                                  0  0.00000000 #> cad_flg                                   0  0.00000000 #> stroke_flg                                0  0.00000000 #> mal_flg                                   0  0.00000000 #> resp_flg                                  0  0.00000000 #> map_1st                                   0  0.00000000 #> hr_1st                                    0  0.00000000 #> temp_1st                                  3  0.16891892 #> spo2_1st                                  0  0.00000000 #> abg_count                                 0  0.00000000 #> wbc_first                                 8  0.45045045 #> hgb_first                                 8  0.45045045 #> platelet_first                            8  0.45045045 #> sodium_first                              5  0.28153153 #> potassium_first                           5  0.28153153 #> tco2_first                                5  0.28153153 #> chloride_first                            5  0.28153153 #> bun_first                                 5  0.28153153 #> creatinine_first                          6  0.33783784 #> po2_first                               186 10.47297297 #> pco2_first                              186 10.47297297 #> iv_day_1                                143  8.05180180 # remove columns with more than 10% missing data and impute the rest with median # Identify columns with more than 10% missing values columns_to_remove <- names(missing_values_percentage[missing_values_percentage > 10])  # Remove these columns mimic <- select(mimic, -one_of(columns_to_remove))  # Impute remaining missing values with median mimic<- mimic %>% mutate(across(where(~any(is.na(.))), ~ifelse(is.na(.), median(., na.rm = TRUE), .)))  # Check if there are any missing values left remaining_missing_values <- sum(sapply(mimic, function(x) sum(is.na(x)))) remaining_missing_values #> [1] 0 # Identify columns that have only one unique value cols_with_one_value <- sapply(mimic, function(x) length(unique(x)) == 1)  # Subset the dataframe to remove these columns mimic <- mimic[, !cols_with_one_value]"},{"path":"https://jianhuig.github.io/FairnessTutorial/articles/TwoGroup.html","id":"model-building","dir":"Articles","previous_headings":"Data Preprocessing","what":"Model Building","title":"Binary Protected Attributes","text":"","code":"# Remove columns that are highly correlated with the outcome variable corrplot(cor(select_if(mimic, is.numeric)), method = \"color\", tl.cex = 0.5) mimic <- mimic %>%    select(-c(\"hosp_exp_flg\", \"icu_exp_flg\", \"mort_day_censored\", \"censor_flg\"))  # Use 700 labels to train the mimic train_data <- mimic %>% filter(row_number() <= 700) # Fit a random forest model set.seed(123) rf_model <- randomForest(factor(day_28_flg) ~ ., data = train_data, ntree = 1000)  # Test the model on the remaining data test_data <- mimic %>% filter(row_number() > 700) test_data$pred <- predict(rf_model, newdata = test_data, type = \"prob\")[,2]"},{"path":"https://jianhuig.github.io/FairnessTutorial/articles/TwoGroup.html","id":"fairness-evaluation","dir":"Articles","previous_headings":"","what":"Fairness Evaluation","title":"Binary Protected Attributes","text":"use sex sensitive attribute day_28_flg outcome. choose threshold = 0.41 overall FPR around 5%.","code":"test_data <- test_data %>%   mutate(gender = ifelse(gender_num == 1, \"Male\", \"Female\")) cut_off <- 0.41  test_data %>%   mutate(pred = ifelse(pred > cut_off, 1, 0)) %>%   filter(day_28_flg == 0) %>%   summarise(fpr = mean(pred)) #>          fpr #> 1 0.05054945"},{"path":[]},{"path":"https://jianhuig.github.io/FairnessTutorial/articles/TwoGroup.html","id":"statistical-parity","dir":"Articles","previous_headings":"Fairness Evaluation > Independence","what":"Statistical Parity","title":"Binary Protected Attributes","text":"","code":"eval_stats_parity(   dat = test_data,   outcome = \"day_28_flg\",   group = \"gender\",   probs = \"pred\",   cutoff = cut_off ) #> There is evidence that model does not satisfy statistical parity. #>   Metric Group Female Group Male Difference  95% Diff CI Ratio 95% Ratio CI #> 1    PPR         0.17       0.08       0.09 [0.05, 0.13]  2.12 [1.48, 3.05]"},{"path":"https://jianhuig.github.io/FairnessTutorial/articles/TwoGroup.html","id":"conditional-statistical-parity","dir":"Articles","previous_headings":"Fairness Evaluation > Independence","what":"Conditional Statistical Parity","title":"Binary Protected Attributes","text":"conditional age >= 60. can also condition categorical variable. example, can condition service unit = MICU.","code":"eval_cond_stats_parity(dat = test_data,   outcome = \"day_28_flg\",   group = \"gender\",   probs = \"pred\",   cutoff = cut_off,   group2 = \"age\",   condition = \">= 60\") #> There is evidence that model does not satisfy statistical parity. #>   Metric Group Female Group Male Difference  95% Diff CI Ratio 95% Ratio CI #> 1    PPR         0.34       0.21       0.13 [0.05, 0.21]  1.62 [1.18, 2.22] eval_cond_stats_parity(dat = test_data,   outcome = \"day_28_flg\",   group = \"gender\",   probs = \"pred\",   cutoff = cut_off,   group2 = \"service_unit\",   condition = \"MICU\") #> There is not enough evidence that the model does not satisfy #>             statistical parity. #>   Metric Group Female Group Male Difference   95% Diff CI Ratio 95% Ratio CI #> 1    PPR         0.15        0.1       0.05 [-0.01, 0.11]   1.5 [0.86, 2.61]"},{"path":[]},{"path":"https://jianhuig.github.io/FairnessTutorial/articles/TwoGroup.html","id":"equal-opportunity","dir":"Articles","previous_headings":"Fairness Evaluation > Separation","what":"Equal Opportunity","title":"Binary Protected Attributes","text":"","code":"eval_eq_opp(   dat = test_data,   outcome = \"day_28_flg\",   group = \"gender\",   probs = \"pred\",   cutoff = cut_off ) #> There is evidence that model does not satisfy equal opportunity. #>   Metric GroupFemale GroupMale Difference    95% Diff CI Ratio 95% Ratio CI #> 1    FNR        0.38      0.62      -0.24 [-0.39, -0.09]  0.61 [0.44, 0.85]"},{"path":"https://jianhuig.github.io/FairnessTutorial/articles/TwoGroup.html","id":"predictive-equality","dir":"Articles","previous_headings":"Fairness Evaluation > Separation","what":"Predictive Equality","title":"Binary Protected Attributes","text":"","code":"eval_pred_equality(   dat = test_data,   outcome = \"day_28_flg\",   group = \"gender\",   probs = \"pred\",   cutoff = cut_off ) #> There is evidence that model does not satisfy predictive #>             equality. #>   Metric GroupFemale GroupMale Difference  95% Diff CI Ratio 95% Ratio CI #> 1    FPR        0.08      0.03       0.05 [0.02, 0.08]  2.67 [1.38, 5.14]"},{"path":"https://jianhuig.github.io/FairnessTutorial/articles/TwoGroup.html","id":"balance-for-positive-class","dir":"Articles","previous_headings":"Fairness Evaluation > Separation","what":"Balance for Positive Class","title":"Binary Protected Attributes","text":"","code":"eval_pos_class_bal(   dat = test_data,   outcome = \"day_28_flg\",   group = \"gender\",   probs = \"pred\" ) #> There is evidence that the model does not satisfy #>             balance for positive class. #>                 Metric GroupFemale GroupMale Difference  95% Diff CI Ratio #> 1 Avg. Predicted Prob.        0.46      0.37       0.09 [0.04, 0.14]  1.24 #>   95% Ratio CI #> 1 [1.09, 1.41]"},{"path":"https://jianhuig.github.io/FairnessTutorial/articles/TwoGroup.html","id":"balance-for-negative-class","dir":"Articles","previous_headings":"Fairness Evaluation > Separation","what":"Balance for Negative Class","title":"Binary Protected Attributes","text":"","code":"eval_neg_class_bal(   dat = test_data,   outcome = \"day_28_flg\",   group = \"gender\",   probs = \"pred\" ) #> There is enough evidence that the model does not satisfy #>             balance for negative class. #>                 Metric GroupFemale GroupMale Difference  95% Diff CI Ratio #> 1 Avg. Predicted Prob.        0.15       0.1       0.05 [0.03, 0.07]   1.5 #>   95% Ratio CI #> 1 [1.29, 1.74]"},{"path":[]},{"path":"https://jianhuig.github.io/FairnessTutorial/articles/TwoGroup.html","id":"predictive-parity","dir":"Articles","previous_headings":"Fairness Evaluation > Sufficiency","what":"Predictive Parity","title":"Binary Protected Attributes","text":"","code":"eval_pred_parity(   dat = test_data,   outcome = \"day_28_flg\",   group = \"gender\",   probs = \"pred\",   cutoff = cut_off ) #> There is not enough evidence that the model does not satisfy #>             predictive parity. #>   Metric GroupFemale GroupMale Difference   95% Diff CI Ratio 95% Ratio CI #> 1    PPV        0.62      0.66      -0.04 [-0.21, 0.13]  0.94 [0.72, 1.23]"},{"path":[]},{"path":"https://jianhuig.github.io/FairnessTutorial/articles/TwoGroup.html","id":"brier-score-parity","dir":"Articles","previous_headings":"Fairness Evaluation > Other Fairness Metrics","what":"Brier Score Parity","title":"Binary Protected Attributes","text":"","code":"eval_bs_parity(   dat = test_data,   outcome = \"day_28_flg\",   group = \"gender\",   probs = \"pred\" ) #> There is not enough evidence that the model does not satisfy #>             Brier Score parity. #>        Metric GroupFemale GroupMale Difference   95% Diff CI Ratio 95% Ratio CI #> 1 Brier Score        0.09      0.08       0.01 [-0.01, 0.03]  1.12 [0.89, 1.43]"},{"path":"https://jianhuig.github.io/FairnessTutorial/articles/TwoGroup.html","id":"accuracy-parity","dir":"Articles","previous_headings":"Fairness Evaluation > Other Fairness Metrics","what":"Accuracy Parity","title":"Binary Protected Attributes","text":"","code":"eval_acc_parity(   dat = test_data,   outcome = \"day_28_flg\",   group = \"gender\",   probs = \"pred\",   cutoff = cut_off ) #> There is not enough evidence that the model does not satisfy #>             accuracy parity. #>     Metric GroupFemale GroupMale Difference   95% Diff CI Ratio 95% Ratio CI #> 1 Accuracy        0.87      0.88      -0.01 [-0.05, 0.03]  0.99 [0.94, 1.04]"},{"path":"https://jianhuig.github.io/FairnessTutorial/articles/TwoGroup.html","id":"treatment-equality","dir":"Articles","previous_headings":"Fairness Evaluation > Other Fairness Metrics","what":"Treatment Equality","title":"Binary Protected Attributes","text":"","code":"eval_treatment_equality(   dat = test_data,   outcome = \"day_28_flg\",   group = \"gender\",   probs = \"pred\" ) #> There is not enough evidence that the model does not satisfy #>             treatment equality. #>        Metric GroupFemale GroupMale Difference     95% Diff CI Ratio #> 1 FN/FP Ratio        5.11      13.6      -8.49 [-33.33, 16.35]  0.38 #>   95% Ratio CI #> 1  [0.1, 1.36]"},{"path":"https://jianhuig.github.io/FairnessTutorial/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jianhui Gao. Author, maintainer. Benson Chou. Author. Jessica Gronsbell. Author.","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Gao J, Chou B, Gronsbell J (2024). FairnessTutorial: tutorial fairness machine learning models healthcare. R package version 1.0.0, https://jianhuig.github.io/FairnessTutorial/.","code":"@Manual{,   title = {FairnessTutorial: A tutorial on fairness of machine learning models in healthcare},   author = {Jianhui Gao and Benson Chou and Jessica Gronsbell},   year = {2024},   note = {R package version 1.0.0},   url = {https://jianhuig.github.io/FairnessTutorial/}, }"},{"path":"https://jianhuig.github.io/FairnessTutorial/index.html","id":"a-tutorial-on-fairness-of-machine-learning-models-in-healthcare","dir":"","previous_headings":"","what":"A tutorial on fairness of machine learning models in healthcare","title":"A tutorial on fairness of machine learning models in healthcare","text":"R package reproducible real-world data examples Fairness Tutorial","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A tutorial on fairness of machine learning models in healthcare","text":"","code":"devtools::install_github(repo = \"https://github.com/jianhuig/FairnessTutorial\")"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_acc_parity.html","id":null,"dir":"Reference","previous_headings":"","what":"Examine accuracy parity of a model — eval_acc_parity","title":"Examine accuracy parity of a model — eval_acc_parity","text":"Examine accuracy parity model","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_acc_parity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examine accuracy parity of a model — eval_acc_parity","text":"","code":"eval_acc_parity(   data,   outcome,   group,   probs,   cutoff = 0.5,   alpha = 0.05,   bootstraps = 2500,   digits = 2,   message = TRUE )"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_acc_parity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Examine accuracy parity of a model — eval_acc_parity","text":"data Data frame containing outcome, predicted outcome, sensitive attribute outcome Name outcome variable group Name sensitive attribute probs Predicted probabilities cutoff Cutoff value predicted probabilities alpha 1 - significance level confidence interval, default 0.05 bootstraps Number bootstraps use confidence intervals digits Number digits round results , default 2 message Whether print results, default TRUE confint Logical indicating whether calculate confidence intervals","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_acc_parity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Examine accuracy parity of a model — eval_acc_parity","text":"list containing following elements: Accuracy Group 1 Accuracy Group 2 Difference accuracy confidence intervals computed (confint = TRUE): vector length 2 containing lower upper bounds 95% confidence interval difference accuracy","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_bs_parity.html","id":null,"dir":"Reference","previous_headings":"","what":"Examine Brier Score parity of a model — eval_bs_parity","title":"Examine Brier Score parity of a model — eval_bs_parity","text":"Examine Brier Score parity model","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_bs_parity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examine Brier Score parity of a model — eval_bs_parity","text":"","code":"eval_bs_parity(   data,   outcome,   group,   probs,   alpha = 0.05,   bootstraps = 2500,   digits = 2,   message = TRUE )"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_bs_parity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Examine Brier Score parity of a model — eval_bs_parity","text":"data Data frame containing outcome, predicted outcome, sensitive attribute outcome Name outcome variable group Name sensitive attribute probs Predicted probabilities alpha 1 - significance level confidence interval, default 0.05 bootstraps Number bootstraps use confidence intervals digits Number digits round results , default 2 message Whether print results, default TRUE confint Logical indicating whether calculate confidence intervals","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_bs_parity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Examine Brier Score parity of a model — eval_bs_parity","text":"list containing following elements: Brier Score Group 1 Brier Score Group 2 Difference Brier Score confidence intervals computed (confint = TRUE): vector length 2 containing lower upper bounds 95% confidence interval difference Brier Score","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_cond_acc_equality.html","id":null,"dir":"Reference","previous_headings":"","what":"Examine conditional use accuracy equality of a model — eval_cond_acc_equality","title":"Examine conditional use accuracy equality of a model — eval_cond_acc_equality","text":"Examine conditional use accuracy equality model","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_cond_acc_equality.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examine conditional use accuracy equality of a model — eval_cond_acc_equality","text":"","code":"eval_cond_acc_equality(   data,   outcome,   group,   probs,   cutoff = 0.5,   alpha = 0.05,   bootstraps = 2500,   digits = 2,   message = TRUE )"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_cond_acc_equality.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Examine conditional use accuracy equality of a model — eval_cond_acc_equality","text":"data Data frame containing outcome, predicted outcome, sensitive attribute outcome Name outcome variable, must binary group Name sensitive attribute probs Name predicted outcome variable cutoff Threshold predicted outcome, default 0.5 alpha 1 - significance level confidence interval, default 0.05 bootstraps Number bootstrap samples, default 2500 digits Number digits round results , default 2 message Whether print results, default TRUE confint Whether compute 95% confidence interval, default TRUE","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_cond_acc_equality.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Examine conditional use accuracy equality of a model — eval_cond_acc_equality","text":"list containing following elements: PPV_Group1: Positive Predictive Value first group PPV_Group2: Positive Predictive Value second group PPV_Diff: Difference Positive Predictive Value NPV_Group1: Negative Predictive Value first group NPV_Group2: Negative Predictive Value second group NPV_Diff: Difference Negative Predictive Value confidence intervals computed (confint = TRUE): PPV_Diff_CI: vector length 2 containing lower upper bounds 95% confidence interval difference Positive Predictive Value NPV_Diff_CI: vector length 2 containing lower upper bounds 95% confidence interval difference Negative Predictive Value","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_cond_stats_parity.html","id":null,"dir":"Reference","previous_headings":"","what":"Examine conditional statistical parity of a model — eval_cond_stats_parity","title":"Examine conditional statistical parity of a model — eval_cond_stats_parity","text":"Examine conditional statistical parity model","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_cond_stats_parity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examine conditional statistical parity of a model — eval_cond_stats_parity","text":"","code":"eval_cond_stats_parity(   data,   outcome,   group,   group2,   condition,   probs,   cutoff = 0.5,   bootstraps = 2500,   alpha = 0.05,   message = TRUE,   digits = 2 )"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_cond_stats_parity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Examine conditional statistical parity of a model — eval_cond_stats_parity","text":"data Data frame containing outcome, predicted outcome, sensitive attribute outcome Name outcome variable, must binary group Name sensitive attribute group2 Name group condition condition conditional group categorical, condition supplied must character levels condition . conditional group continuous, conditions supplied must character containing sign condition value threshold continuous variable (e.g. \"<50\", \">50\", \"<=50\", \">=50\"). probs Name predicted outcome variable cutoff Threshold predicted outcome, default 0.5 bootstraps Number bootstrap samples, default 2500 alpha 1 - significance level confidence interval, default 0.05 message Whether print results, default TRUE digits Number digits round results , default 2","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_cond_stats_parity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Examine conditional statistical parity of a model — eval_cond_stats_parity","text":"list containing following elements: Conditions: conditions used calculate conditional PPR PPR_Group1: Positive Prediction Rate first group PPR_Group2: Positive Prediction Rate second group PPR_Diff: Difference Positive Prediction Rate confidence intervals computed (confint = TRUE): PPR_Diff_CI: vector length 2 containing lower upper bounds 95% confidence interval difference Positive Prediction Rate","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_eq_odds.html","id":null,"dir":"Reference","previous_headings":"","what":"Examine Equalized Odds of a Predictive Model — eval_eq_odds","title":"Examine Equalized Odds of a Predictive Model — eval_eq_odds","text":"function examines equalized odds predictive model comparing False Negative Rates (FNR) False Positive Rates (FPR) across different groups defined sensitive attribute. assesses model performs unbiasedly binary outcomes across groups, adhering equalized odds fairness criterion.","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_eq_odds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examine Equalized Odds of a Predictive Model — eval_eq_odds","text":"","code":"eval_eq_odds(   data,   outcome,   group,   probs,   cutoff = 0.5,   bootstraps = 2500,   alpha = 0.05,   digits = 2,   message = TRUE )"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_eq_odds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Examine Equalized Odds of a Predictive Model — eval_eq_odds","text":"data dataframe containing actual outcomes, predicted outcomes, sensitive attributes necessary evaluating model fairness. outcome name outcome variable data; must binary. group name sensitive attribute variable used define groups comparison fairness evaluation. probs name variable containing predicted probabilities scores. cutoff threshold converting predicted probabilities binary predictions; defaults 0.5. bootstraps number bootstrap samples used estimating uncertainty fairness metrics; defaults 1000. alpha 1 - significance level confidence interval; defaults 0.05. digits number decimal places numerical results rounded; defaults 2. message Logical; whether print summary results console; defaults TRUE.","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_eq_odds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Examine Equalized Odds of a Predictive Model — eval_eq_odds","text":"Returns dataframe following columns: Metric: Describes metric reported (FNR FPR group, difference). Group1: Rate first group. Group2: Rate second group. Difference: difference rates two groups. 95% CI: 95% confidence interval rate difference。","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_eq_odds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Examine Equalized Odds of a Predictive Model — eval_eq_odds","text":"","code":"# Example usage: eval_eq_odds(   data = your_data, outcome = \"actual_outcome\",   group = \"sensitive_attribute\", probs = \"predicted_probs\" ) #> Error in eval(expr, envir, enclos): object 'your_data' not found"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_eq_opp.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate Equal Opportunity Compliance of a Predictive Model — eval_eq_opp","title":"Evaluate Equal Opportunity Compliance of a Predictive Model — eval_eq_opp","text":"function evaluates equal opportunity compliance predictive model comparing False Negative Rates (FNR) across different groups defined sensitive attribute. used determine model exhibits bias towards group binary outcomes.","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_eq_opp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate Equal Opportunity Compliance of a Predictive Model — eval_eq_opp","text":"","code":"eval_eq_opp(   data,   outcome,   group,   probs,   cutoff = 0.5,   bootstraps = 2500,   alpha = 0.05,   digits = 2,   message = TRUE )"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_eq_opp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate Equal Opportunity Compliance of a Predictive Model — eval_eq_opp","text":"data dataframe containing actual outcomes, predicted probabilities, sensitive attributes necessary evaluating model fairness. outcome name outcome variable data; must binary. group name sensitive attribute variable used define groups comparison fairness evaluation. probs name variable containing predicted probabilities scores. cutoff threshold converting predicted probabilities binary predictions; defaults 0.5. bootstraps number bootstrap samples used estimating confidence interval; defaults 2500. alpha 1 - significance level confidence interval; defaults 0.05. digits number decimal places numerical results rounded; defaults 2. message Logical; whether print summary results console; defaults TRUE.","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_eq_opp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate Equal Opportunity Compliance of a Predictive Model — eval_eq_opp","text":"Returns dataframe following columns: Metric: Describes metric reported (FNR group, difference). Group1: False Negative Rate first group. Group2: False Negative Rate second group. Difference: difference False Negative Rates two groups. CI: 95% confidence interval FNR difference.","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_eq_opp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate Equal Opportunity Compliance of a Predictive Model — eval_eq_opp","text":"","code":"# Example usage: eval_eq_opp(   data = your_data, outcome = \"actual_outcome\",   group = \"sensitive_attribute\", probs = \"predicted_probs\" ) #> Error in eval(expr, envir, enclos): object 'your_data' not found"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_generalized_entropy_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Examine Generalized Entropy Index of a model #' This function evaluates the generalized entropy index in model performance metrics across different groups. — eval_generalized_entropy_index","title":"Examine Generalized Entropy Index of a model #' This function evaluates the generalized entropy index in model performance metrics across different groups. — eval_generalized_entropy_index","text":"Examine Generalized Entropy Index model #' function evaluates generalized entropy index model performance metrics across different groups.","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_generalized_entropy_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examine Generalized Entropy Index of a model #' This function evaluates the generalized entropy index in model performance metrics across different groups. — eval_generalized_entropy_index","text":"","code":"eval_generalized_entropy_index(   data,   outcome,   group,   probs,   alpha = 2,   cutoff = 0.5,   digits = 2 )"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_generalized_entropy_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Examine Generalized Entropy Index of a model #' This function evaluates the generalized entropy index in model performance metrics across different groups. — eval_generalized_entropy_index","text":"data Data frame containing outcome, predicted outcome, group outcome Name outcome variable, must binary group Name group probs Name predicted outcome variable cutoff Threshold predicted outcome, default 0.5 digits Number digits round results , default 2","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_generalized_entropy_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Examine Generalized Entropy Index of a model #' This function evaluates the generalized entropy index in model performance metrics across different groups. — eval_generalized_entropy_index","text":"data frame containing following elements: Metric: names metrics calculated. Values group. Generalized_entropy_index: generalized entropy index model","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_max_abs_diff.html","id":null,"dir":"Reference","previous_headings":"","what":"Examine max absolute difference of a model — eval_max_abs_diff","title":"Examine max absolute difference of a model — eval_max_abs_diff","text":"function evaluates maximum absolute difference model performance metrics across different groups.","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_max_abs_diff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examine max absolute difference of a model — eval_max_abs_diff","text":"","code":"eval_max_abs_diff(data, outcome, group, probs, cutoff = 0.5, digits = 2)"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_max_abs_diff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Examine max absolute difference of a model — eval_max_abs_diff","text":"data Data frame containing outcome, predicted outcome, group outcome Name outcome variable, must binary group Name group probs Name predicted outcome variable cutoff Threshold predicted outcome, default 0.5 digits Number digits round results , default 2","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_max_abs_diff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Examine max absolute difference of a model — eval_max_abs_diff","text":"data frame containing following elements: Metric: names metrics calculated. Values group. Max_abs_diff: maximum absolute difference model","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_max_min_diff.html","id":null,"dir":"Reference","previous_headings":"","what":"Examine Maximum-Minimum Difference of a Model — eval_max_min_diff","title":"Examine Maximum-Minimum Difference of a Model — eval_max_min_diff","text":"function evaluates maximum minimum differences model performance metrics across different groups.","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_max_min_diff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examine Maximum-Minimum Difference of a Model — eval_max_min_diff","text":"","code":"eval_max_min_diff(data, outcome, group, probs, cutoff = 0.5, digits = 2)"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_max_min_diff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Examine Maximum-Minimum Difference of a Model — eval_max_min_diff","text":"data Data frame containing outcome, predicted outcome, group. outcome Name outcome variable, must binary. group Name group variable. probs Name predicted outcome variable. cutoff Threshold predicted outcome, default 0.5. digits Number digits round results , default 2.","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_max_min_diff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Examine Maximum-Minimum Difference of a Model — eval_max_min_diff","text":"data frame containing following elements: Metric: names metrics calculated. Values group. Max-Min: maximum minus minimum metric difference model.","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_max_min_ratio.html","id":null,"dir":"Reference","previous_headings":"","what":"Examine Maximum Minimum Ratio of a model — eval_max_min_ratio","title":"Examine Maximum Minimum Ratio of a model — eval_max_min_ratio","text":"function evaluates maximum minimum ratio model performance metrics across different groups.","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_max_min_ratio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examine Maximum Minimum Ratio of a model — eval_max_min_ratio","text":"","code":"eval_max_min_ratio(data, outcome, group, probs, cutoff = 0.5, digits = 2)"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_max_min_ratio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Examine Maximum Minimum Ratio of a model — eval_max_min_ratio","text":"data Data frame containing outcome, predicted outcome, group outcome Name outcome variable, must binary group Name group probs Name predicted outcome variable cutoff Threshold predicted outcome, default 0.5 digits Number digits round results , default 2","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_max_min_ratio.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Examine Maximum Minimum Ratio of a model — eval_max_min_ratio","text":"data frame containing following elements: Metric: names metrics calculated. Values group. Max/Min: maximum minimum metric difference model","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_mean_abs_dev.html","id":null,"dir":"Reference","previous_headings":"","what":"Examine mean absolute deviation of a model #' This function evaluates the mean absolute deviation in model performance metrics across different groups. — eval_mean_abs_dev","title":"Examine mean absolute deviation of a model #' This function evaluates the mean absolute deviation in model performance metrics across different groups. — eval_mean_abs_dev","text":"Examine mean absolute deviation model #' function evaluates mean absolute deviation model performance metrics across different groups.","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_mean_abs_dev.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examine mean absolute deviation of a model #' This function evaluates the mean absolute deviation in model performance metrics across different groups. — eval_mean_abs_dev","text":"","code":"eval_mean_abs_dev(data, outcome, group, probs, cutoff = 0.5, digits = 2)"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_mean_abs_dev.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Examine mean absolute deviation of a model #' This function evaluates the mean absolute deviation in model performance metrics across different groups. — eval_mean_abs_dev","text":"data Data frame containing outcome, predicted outcome, group outcome Name outcome variable, must binary group Name group probs Name predicted outcome variable cutoff Threshold predicted outcome, default 0.5 digits Number digits round results , default 2","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_mean_abs_dev.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Examine mean absolute deviation of a model #' This function evaluates the mean absolute deviation in model performance metrics across different groups. — eval_mean_abs_dev","text":"data frame containing following elements: Metric: names metrics calculated. Values group. Mean_abs_dev: mean absolute deviation model","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_neg_class_bal.html","id":null,"dir":"Reference","previous_headings":"","what":"Examine balance for negative class of a model — eval_neg_class_bal","title":"Examine balance for negative class of a model — eval_neg_class_bal","text":"Examine balance negative class model","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_neg_class_bal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examine balance for negative class of a model — eval_neg_class_bal","text":"","code":"eval_neg_class_bal(   data,   outcome,   group,   probs,   alpha = 0.05,   bootstraps = 2500,   digits = 2,   message = TRUE )"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_neg_class_bal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Examine balance for negative class of a model — eval_neg_class_bal","text":"data Data frame containing outcome, predicted outcome, sensitive attribute outcome Name outcome variable group Name sensitive attribute probs Predicted probabilities alpha 1 - significance level confidence interval, default 0.05 bootstraps Number bootstraps use confidence intervals digits Number digits round results , default 2 message Whether print results, default TRUE confint Logical indicating whether calculate confidence intervals","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_neg_class_bal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Examine balance for negative class of a model — eval_neg_class_bal","text":"list containing following elements: Average predicted probability Group 1 Average predicted probability Group 2 Difference average predicted probability confidence intervals computed (confint = TRUE): vector length 2 containing lower upper bounds 95% confidence interval difference average predicted probability","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_pos_class_bal.html","id":null,"dir":"Reference","previous_headings":"","what":"Examine balance for positive class of a model — eval_pos_class_bal","title":"Examine balance for positive class of a model — eval_pos_class_bal","text":"Examine balance positive class model","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_pos_class_bal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examine balance for positive class of a model — eval_pos_class_bal","text":"","code":"eval_pos_class_bal(   data,   outcome,   group,   probs,   alpha = 0.05,   bootstraps = 2500,   digits = 2,   message = TRUE )"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_pos_class_bal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Examine balance for positive class of a model — eval_pos_class_bal","text":"data Data frame containing outcome, predicted outcome, sensitive attribute outcome Name outcome variable group Name sensitive attribute probs Predicted probabilities alpha 1 - significance level confidence interval, default 0.05 bootstraps Number bootstraps use confidence intervals digits Number digits round results , default 2 message Whether print results, default TRUE confint Logical indicating whether calculate confidence intervals","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_pos_class_bal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Examine balance for positive class of a model — eval_pos_class_bal","text":"list containing following elements: Average predicted probability Group 1 Average predicted probability Group 2 Difference average predicted probability confidence intervals computed (confint = TRUE): vector length 2 containing lower upper bounds 95% confidence interval difference average predicted probability","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_pred_equality.html","id":null,"dir":"Reference","previous_headings":"","what":"Examine predictive equality of a model — eval_pred_equality","title":"Examine predictive equality of a model — eval_pred_equality","text":"Examine predictive equality model","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_pred_equality.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examine predictive equality of a model — eval_pred_equality","text":"","code":"eval_pred_equality(   data,   outcome,   group,   probs,   cutoff = 0.5,   alpha = 0.05,   bootstraps = 2500,   digits = 2,   message = TRUE )"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_pred_equality.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Examine predictive equality of a model — eval_pred_equality","text":"data Data frame containing outcome, predicted outcome, sensitive attribute outcome Name outcome variable, must binary group Name sensitive attribute probs Name predicted outcome variable cutoff Threshold predicted outcome, default 0.5 alpha 1 - significance level confidence interval, default 0.05 bootstraps Number bootstrap samples, default 2500 digits Number digits round results , default 2 message Whether print results, default TRUE confint Whether compute 95% confidence interval, default TRUE","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_pred_equality.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Examine predictive equality of a model — eval_pred_equality","text":"list containing following elements: FPR_Group1: False Positive Rate first group FPR_Group2: False Positive Rate second group FPR_Diff: Difference False Positive Rate confidence intervals computed (confint = TRUE): FPR_Diff_CI: vector length 2 containing lower upper bounds 95% confidence interval difference False Positive Rate","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_pred_parity.html","id":null,"dir":"Reference","previous_headings":"","what":"Examine predictive parity of a model — eval_pred_parity","title":"Examine predictive parity of a model — eval_pred_parity","text":"Examine predictive parity model","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_pred_parity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examine predictive parity of a model — eval_pred_parity","text":"","code":"eval_pred_parity(   data,   outcome,   group,   probs,   cutoff = 0.5,   bootstraps = 2500,   alpha = 0.05,   digits = 2,   message = TRUE )"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_pred_parity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Examine predictive parity of a model — eval_pred_parity","text":"data Data frame containing outcome, predicted outcome, sensitive attribute outcome Name outcome variable, must binary group Name sensitive attribute probs Name predicted outcome variable cutoff Threshold predicted outcome, default 0.5 bootstraps Number bootstrap samples, default 2500 alpha 1 - significance level confidence interval, default 0.05 digits Number digits round results , default 2 message Whether print results, default TRUE confint Whether compute 95% confidence interval, default TRUE","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_pred_parity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Examine predictive parity of a model — eval_pred_parity","text":"list containing following elements: PPV_Group1: Positive Predictive Value first group PPV_Group2: Positive Predictive Value second group PPV_Diff: Difference Positive Predictive Value confidence intervals computed (confint = TRUE): PPV_Diff_CI: vector length 2 containing lower upper bounds 95% confidence interval difference Positive Predictive Value","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_stats_parity.html","id":null,"dir":"Reference","previous_headings":"","what":"Examine statistical parity of a model — eval_stats_parity","title":"Examine statistical parity of a model — eval_stats_parity","text":"Examine statistical parity model","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_stats_parity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examine statistical parity of a model — eval_stats_parity","text":"","code":"eval_stats_parity(   data,   outcome,   group,   probs,   cutoff = 0.5,   bootstraps = 2500,   alpha = 0.05,   digits = 2,   message = TRUE )"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_stats_parity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Examine statistical parity of a model — eval_stats_parity","text":"data Data frame containing outcome, predicted outcome, sensitive attribute outcome Name outcome variable, must binary group Name sensitive attribute probs Name predicted outcome variable cutoff Threshold predicted outcome, default 0.5 bootstraps Number bootstrap samples, default 2500 alpha 1 - significance level confidence interval, default 0.05 digits Number digits round results , default 2 message Whether print results, default TRUE confint Whether compute 95% confidence interval, default TRUE","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_stats_parity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Examine statistical parity of a model — eval_stats_parity","text":"list containing following elements: PPR_Group1: Positive Prediction Rate first group PPR_Group2: Positive Prediction Rate second group PPR_Diff: Difference Positive Prediction Rate confidence intervals computed (confint = TRUE): PPR_Diff_CI: vector length 2 containing lower upper bounds 95% confidence interval difference Positive Prediction Rate","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_treatment_equality.html","id":null,"dir":"Reference","previous_headings":"","what":"Examine treatment equality of a model — eval_treatment_equality","title":"Examine treatment equality of a model — eval_treatment_equality","text":"Examine treatment equality model","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_treatment_equality.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examine treatment equality of a model — eval_treatment_equality","text":"","code":"eval_treatment_equality(   data,   outcome,   group,   probs,   cutoff = 0.5,   alpha = 0.05,   bootstraps = 2500,   digits = 2,   message = TRUE )"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_treatment_equality.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Examine treatment equality of a model — eval_treatment_equality","text":"data Data frame containing outcome, predicted outcome, sensitive attribute outcome Name outcome variable group Name sensitive attribute probs Predicted probabilities cutoff Cutoff value predicted probabilities alpha 1 - significance level confidence interval, default 0.05 bootstraps Number bootstraps use confidence intervals digits Number digits round results , default 2 message Whether print results, default TRUE confint Logical indicating whether calculate confidence intervals","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_treatment_equality.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Examine treatment equality of a model — eval_treatment_equality","text":"list containing following elements: False Negative / False Positive ratio Group 1 False Negative / False Positive ratio Group 2 Difference False Negative / False Positive ratio confidence intervals computed (confint = TRUE): vector length 2 containing lower upper bounds 95% confidence interval difference False Negative / False Positive ratio","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_variance.html","id":null,"dir":"Reference","previous_headings":"","what":"Examine variance of a model #' This function evaluates the variance in model performance metrics across different groups. — eval_variance","title":"Examine variance of a model #' This function evaluates the variance in model performance metrics across different groups. — eval_variance","text":"Examine variance model #' function evaluates variance model performance metrics across different groups.","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_variance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examine variance of a model #' This function evaluates the variance in model performance metrics across different groups. — eval_variance","text":"","code":"eval_variance(data, outcome, group, probs, cutoff = 0.5, digits = 2)"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_variance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Examine variance of a model #' This function evaluates the variance in model performance metrics across different groups. — eval_variance","text":"data Data frame containing outcome, predicted outcome, group outcome Name outcome variable, must binary group Name group probs Name predicted outcome variable cutoff Threshold predicted outcome, default 0.5 digits Number digits round results , default 2","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/eval_variance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Examine variance of a model #' This function evaluates the variance in model performance metrics across different groups. — eval_variance","text":"data frame containing following elements: Metric: names metrics calculated. Values group. Variance: variance model","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/get_all_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the all metrics at once — get_all_metrics","title":"Calculate the all metrics at once — get_all_metrics","text":"Calculate metrics ","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/get_all_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the all metrics at once — get_all_metrics","text":"","code":"get_all_metrics(data, outcome, group, probs, cutoff = 0.5, digits = 2)"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/get_all_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the all metrics at once — get_all_metrics","text":"data Data frame containing outcome, predicted outcome, sensitive attribute outcome name outcome variable, must binary group name sensitive attribute probs name predicted outcome variable cutoff threshold predicted outcome, default 0.5 digits number digits round result , default 2","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/get_all_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the all metrics at once — get_all_metrics","text":"Data frame metrics","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/mimic.html","id":null,"dir":"Reference","previous_headings":"","what":"Clinical data from the MIMIC-II database for a case study on indwelling arterial catheters — mimic","title":"Clinical data from the MIMIC-II database for a case study on indwelling arterial catheters — mimic","text":"Indwelling Arterial Catheter Clinical dataset contains clinical data 1776 patients MIMIC-II clinical database. basis article: Hsu DJ, et al. association indwelling arterial catheters mortality hemodynamically stable patients respiratory failure: propensity score analysis. Chest, 148(6):1470–1476, Aug. 2015. dataset also used Raffa et al. Chapter 5 \"Data Analysis\" forthcoming book: Secondary Analysis Electronic Health Records, published Springer 2016.","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/mimic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clinical data from the MIMIC-II database for a case study on indwelling arterial catheters — mimic","text":"","code":"mimic"},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/mimic.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Clinical data from the MIMIC-II database for a case study on indwelling arterial catheters — mimic","text":"data frame 1776 rows 46 variables: aline_flg Integer, indicates IAC used (1 = yes, 0 = ) icu_los_day Double, length stay ICU (days) hospital_los_day Integer, length stay hospital (days) age Double, age baseline (years) gender_num Integer, patient gender (1 = male; 0 = female) weight_first Double, first weight (kg) bmi Double, patient BMI sapsi_first Integer, first SAPS score sofa_first Integer, first SOFA score service_unit Character, type service unit (FICU, MICU, SICU) service_num Integer, service numeric value (0 = MICU FICU, 1 = SICU) day_icu_intime Character, day week ICU admission day_icu_intime_num Integer, day week ICU admission (numeric) hour_icu_intime Integer, hour ICU admission (24hr clock) hosp_exp_flg Integer, death hospital (1 = yes, 0 = ) icu_exp_flg Integer, death ICU (1 = yes, 0 = ) day_28_flg Integer, death within 28 days (1 = yes, 0 = ) mort_day_censored Double, day post ICU admission censoring death (days) censor_flg Integer, censored death (0 = death, 1 = censored) sepsis_flg Integer, sepsis present (0 = , 1 = yes) chf_flg Integer, congestive heart failure (0 = , 1 = yes) afib_flg Integer, atrial fibrillation (0 = , 1 = yes) renal_flg Integer, chronic renal disease (0 = , 1 = yes) liver_flg Integer, liver disease (0 = , 1 = yes) copd_flg Integer, chronic obstructive pulmonary disease (0 = , 1 = yes) cad_flg Integer, coronary artery disease (0 = , 1 = yes) stroke_flg Integer, stroke (0 = , 1 = yes) mal_flg Integer, malignancy (0 = , 1 = yes) resp_flg Integer, respiratory disease (non-COPD) (0 = , 1 = yes) map_1st Double, mean arterial pressure (mmHg) hr_1st Integer, heart rate temp_1st Double, temperature (F) spo2_1st Integer, S_pO_2 (percent) abg_count Integer, arterial blood gas count (number tests) wbc_first Double, first white blood cell count (K/uL) hgb_first Double, first hemoglobin (g/dL) platelet_first Integer, first platelets (K/u) sodium_first Integer, first sodium (mEq/L) potassium_first Double, first potassium (mEq/L) tco2_first Double, first bicarbonate (mEq/L) chloride_first Integer, first chloride (mEq/L) bun_first Integer, first blood urea nitrogen (mg/dL) creatinine_first Double, first creatinine (mg/dL) po2_first Integer, first PaO_2 (mmHg) pco2_first Integer, first PaCO_2 (mmHg) iv_day_1 Double, input fluids IV day 1 (mL)","code":""},{"path":"https://jianhuig.github.io/FairnessTutorial/reference/mimic.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Clinical data from the MIMIC-II database for a case study on indwelling arterial catheters — mimic","text":"https://physionet.org/content/mimic2-iaccd/1.0/","code":""}]
