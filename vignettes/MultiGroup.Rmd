---
title: "MultiGroup"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{MultiGroup}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(FairnessTutorial)
library(PheCAP)
library(dplyr)
library(caret)
library(glmnet)
```

# Data Preprocessing

## Missing Data and Splitting Into Groups

```{r}
data <- PheCAP::PhecapData(ehr_data, "healthcare_utilization", "label", 0.4)$frame
# Binarize outcome (main_ICD)
data <- data %>% mutate(outcome = ifelse(main_ICD > 0, 1, 0))
# Split data into groups (1, 2, 3, 4) based on healthcare_utilization quantiles
data <- data %>% mutate(HU_group = ifelse(healthcare_utilization <= quantile(healthcare_utilization, 0.25), 1,
                                          ifelse(healthcare_utilization <= quantile(healthcare_utilization, 0.5), 2,
                                                 ifelse(healthcare_utilization <= quantile(healthcare_utilization, 0.75), 3, 4))))
# Keep only interested
target_data <- data %>% select(outcome, main_NLP, HU_group, healthcare_utilization, starts_with("NLP"))
# Check if any missing data
sum(is.na(target_data))
```

## Model Building

```{r}
# 75% of the sample size
train_size <- floor(0.75 * nrow(target_data))
# Split data
set.seed(321)
train_ind <- sample(seq_len(nrow(target_data)), size=train_size)
train <- target_data[train_ind, ]
x_train <- as.matrix(train %>% select(-outcome, -HU_group))
y_train <- as.matrix(train %>% select(outcome))

test <- target_data[-train_ind, ]
x_test <- as.matrix(test %>% select(-outcome, -HU_group))
y_test <- test %>% select(outcome)

# Manually create 10-folds to make sure the results are reproducible
set.seed(30)
folds <- createFolds(y_train, k = 10, list = TRUE)

# Convert the list to a vector where each element indicates the fold number
fold_ids <- rep(NA, length(y_train))
for(i in 1:10) {
  fold_ids[folds[[i]]] <- i
}

# To choose lambda (regularization parameter), cross-validation is typically used
# Pass the fold_ids to cv.glmnet through the foldid argument
cv_fit <- cv.glmnet(x_train, y_train, family = "binomial", alpha = 1, foldid = fold_ids)

# Best lambda value
best_lambda <- cv_fit$lambda.min

# Fit logistic Regression
fit <- glmnet::glmnet(x_train, y_train, family = "binomial", alpha=1, lambda = best_lambda)

# Predictions
test$pred <- predict(fit, newx = x_test, type = "response", s = best_lambda)[,1]
mean(ifelse(test$pred > 0.4, 1, 0) == y_test)
```

# Multi-Group Fairness Evaluation

We will use hu_group as the sensitive attribute and outcome as the outcome

```{r}
# Categorize the group
test <- test %>%
  mutate(hu_group = ifelse(HU_group == 1, paste0("0 to ", quantile(data$healthcare_utilization, 0.25)),
                           ifelse(HU_group ==2, paste0(quantile(data$healthcare_utilization, 0.25), " to ", quantile(data$healthcare_utilization, 0.5)),
                                  ifelse(HU_group == 3, paste0(quantile(data$healthcare_utilization, 0.5), " to ", quantile(data$healthcare_utilization, 0.75)), paste0(quantile(data$healthcare_utilization, 0.75), " to ", quantile(data$healthcare_utilization, 1))))))

# The dataframe would need predictions, outcome, HU_group
test <- test %>% select(outcome, pred, HU_group)
```

We choose threshold = 0.65 so that the overall FPR is around 5%.

```{r}
cut_off <- 0.65

test %>% 
  mutate(pred = ifelse(pred > cut_off, 1, 0)) %>% 
  filter(outcome == 0) %>% 
  summarise(fpr = mean(pred))
```

## Max-Min Difference

```{r}
eval_max_min_diff(data = test, 
                  outcome = "outcome", 
                  probs = "pred",
                  group = "HU_group",
                  bootstraps = 1000)
```

## Max-Min Ratio

```{r}
eval_max_min_ratio(data = test, 
                  outcome = "outcome", 
                  probs = "pred",
                  group = "HU_group",
                  bootstraps = 1000)
```

## Max Absolute Difference

```{r}
eval_max_abs_diff(data = test, 
                  outcome = "outcome", 
                  probs = "pred",
                  group = "HU_group",
                  bootstraps = 1000)
```

## Mean Absolute Deviation

```{r}
eval_mean_abs_dev(data = test, 
                  outcome = "outcome", 
                  probs = "pred",
                  group = "HU_group",
                  bootstraps = 1000)
```

## Variance

```{r}
eval_variance(data = test, 
                  outcome = "outcome", 
                  probs = "pred",
                  group = "HU_group",
                  bootstraps = 1000)
```

## Generalized Entropy Index

```{r}
eval_generalized_entropy_index(data = test, 
                  outcome = "outcome", 
                  probs = "pred",
                  group = "HU_group",
                  bootstraps = 1000)
```
