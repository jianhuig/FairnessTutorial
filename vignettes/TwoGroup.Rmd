---
title: "Binary Protected Attributes"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Binary Protected Attributes}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, message=FALSE, warning=FALSE}
library(FairnessTutorial)
library(dplyr)
library(corrplot)
library(randomForest)
library(pROC)
library(SpecsVerification)

data("mimic")
```

# Data Preprocessing

## Missing Data

```{r}
# Calculate the number of missing values per column
missing_values <- sapply(mimic, function(x) sum(is.na(x)))

# Calculate the percentage of missing values per column
missing_values_percentage <- sapply(mimic, function(x) sum(is.na(x)) / length(x) * 100)

# Combine the results into a data frame for easy viewing
missing_data_summary <- data.frame(Number_of_Missing_Values = missing_values, 
                                   Percentage = missing_values_percentage)

# Print the summary
print(missing_data_summary)

# remove columns with more than 10% missing data and impute the rest with median
# Identify columns with more than 10% missing values
columns_to_remove <- names(missing_values_percentage[missing_values_percentage > 10])

# Remove these columns
mimic <- select(mimic, -one_of(columns_to_remove))

# Impute remaining missing values with median
mimic<- mimic %>% mutate(across(where(~any(is.na(.))), ~ifelse(is.na(.), median(., na.rm = TRUE), .)))

# Check if there are any missing values left
remaining_missing_values <- sum(sapply(mimic, function(x) sum(is.na(x))))
remaining_missing_values

# Identify columns that have only one unique value
cols_with_one_value <- sapply(mimic, function(x) length(unique(x)) == 1)

# Subset the dataframe to remove these columns
mimic <- mimic[, !cols_with_one_value]
```

## Model Building

```{r}
# Remove columns that are highly correlated with the outcome variable
corrplot(cor(select_if(mimic, is.numeric)), method = "color", tl.cex = 0.5)
mimic <- mimic %>% 
  select(-c("hosp_exp_flg", "icu_exp_flg", "mort_day_censored", "censor_flg"))

# Use 700 labels to train the mimic
train_data <- mimic %>% filter(row_number() <= 700)
# Fit a random forest model
set.seed(123)
rf_model <- randomForest(factor(day_28_flg) ~ ., data = train_data, ntree = 1000)

# Test the model on the remaining data
test_data <- mimic %>% filter(row_number() > 700)
test_data$pred <- predict(rf_model, newdata = test_data, type = "prob")[,2]
```

# Fairness Evaluation

We will use sex as the sensitive attribute and day_28_flg as the outcome.

```{r}
test_data <- test_data %>%
  mutate(gender = ifelse(gender_num == 1, "Male", "Female"))
```

We choose threshold = 0.41 so that the overall FPR is around 5%.

```{r}
cut_off <- 0.41

test_data %>%
  mutate(pred = ifelse(pred > cut_off, 1, 0)) %>%
  filter(day_28_flg == 0) %>%
  summarise(fpr = mean(pred))
```

## Equal Opportunity

```{r}
eval_eq_opp(
  dat = test_data,
  outcome = "day_28_flg",
  group = "gender",
  probs = "pred",
  cutoff = cut_off, 
  message = TRUE
)
```

## Equalized Odds

```{r}
eval_eq_odds(
  dat = test_data,
  outcome = "day_28_flg",
  group = "gender",
  probs = "pred",
  cutoff = cut_off
)
```

## Statistical Parity

```{r}
eval_stats_parity(
  dat = test_data,
  outcome = "day_28_flg",
  group = "gender",
  probs = "pred",
  cutoff = cut_off
)
```

## Conditional Statistical Parity

We conditional on age >= 60.

```{r}
eval_cond_stats_parity(dat = test_data,
  outcome = "day_28_flg",
  group = "gender",
  probs = "pred",
  cutoff = cut_off,
  group2 = "age",
  condition = ">= 60")
```

We can also condition on a categorical variable. For example, we can condition on the service unit = MICU.


```{r}
eval_cond_stats_parity(dat = test_data,
  outcome = "day_28_flg",
  group = "gender",
  probs = "pred",
  cutoff = cut_off,
  group2 = "service_unit",
  condition = "MICU")
```

## Predictive Parity

```{r}
eval_pred_parity(
  dat = test_data,
  outcome = "day_28_flg",
  group = "gender",
  probs = "pred",
  cutoff = cut_off
)
```

## Predictive Equality

```{r}
eval_pred_equality(
  dat = test_data,
  outcome = "day_28_flg",
  group = "gender",
  probs = "pred",
  cutoff = cut_off
)
```

## Conditional Accuracy Equality

```{r}
eval_cond_acc_equality(
  dat = test_data,
  outcome = "day_28_flg",
  group = "gender",
  probs = "pred",
  cutoff = cut_off
)
```

## Accuracy Parity

```{r}
eval_acc_parity(
  dat = test_data,
  outcome = "day_28_flg",
  group = "gender",
  probs = "pred",
  cutoff = cut_off
)
```

## Brier Score Parity

```{r}
eval_bs_parity(
  dat = test_data,
  outcome = "day_28_flg",
  group = "gender",
  probs = "pred"
)
```

## Treatment Equality

```{r}
eval_treatment_equality(
  dat = test_data,
  outcome = "day_28_flg",
  group = "gender",
  probs = "pred"
)
```

## Balance for Positive Class

```{r}
eval_pos_class_bal(
  dat = test_data,
  outcome = "day_28_flg",
  group = "gender",
  probs = "pred"
)
```

## Balance for Negative Class

```{r}
eval_neg_class_bal(
  dat = test_data,
  outcome = "day_28_flg",
  group = "gender",
  probs = "pred"
)
```
